{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090acb0b5c7847e8a08d46597af75629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"yanolja/EEVE-Korean-Instruct-2.8B-v1.0\")\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"yanolja/EEVE-Korean-Instruct-10.8B-v1.0\", device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yanolja/EEVE-Korean-Instruct-10.8B-v1.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): Embedding(58944, 2560)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x PhiDecoderLayer(\n",
       "        (self_attn): PhiSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=58944, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.half()\n",
    "model.to(device)\n",
    "# tokenizer.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:58943 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a natural language understanding assistant tasked with creating sentences for a dataset. Your job is to read the given first sentence and then generate three different second sentences: one that is neutral, one that is a contradiction, and one that is an entailment.     You need to make sentences in korean.     \n",
      " This is examples:     sentence1\tsentence2\tgold_label     그리고 그가 말했다, \"엄마, 저 왔어요.\"\t그는 학교 버스가 그를 내려주자마자 엄마에게 전화를 걸었다.\tneutral\n",
      "     그리고 그가 말했다, \"엄마, 저 왔어요.\"\t그는 한마디도 하지 않았다.\tcontradiction\n",
      "     그리고 그가 말했다, \"엄마, 저 왔어요.\"\t그는 엄마에게 집에 갔다고 말했다.\tentailment\n",
      "     내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 지정된 장소에 보고해야 했습니다.\t나는 워싱턴에 가본 적이 없어서 거기 배정을 받았을 때 그 장소를 찾으려다가 길을 잃었어요.\tneutral\n",
      "     내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 지정된 장소에 보고해야 했습니다.\t워싱턴으로 진군하면서 해야 할 일이 무엇인지 정확히 알고 있었다.\tcontradiction\n",
      "     내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 지정된 장소에 보고해야 했습니다.\t나는 내가 무엇을 할 것인지 확신할 수 없어서 내가 보고를 하도록 배정받은 워싱턴으로 갔다.\tentailment\n",
      "     그는 갈 수 없었다.\t그는 처음 초대를 받은 사람이고 그 경험을 즐겼다.\tcontradiction\n",
      "     그는 갈 수 없었다.\t그는 참석하는 것을 허가받지 않았다.\tentailment\n",
      "     그는 갈 수 없었다.\t그는 박물관 개관식에 가는 것이 허용되지 않았다.\tneutral\n",
      "     그리고 저는 \"괜찮아\" 하고, 그게 다였어요!\t내가 승낙한 후에, 그것은 끝났다.\tentailment\n",
      "     그리고 저는 \"괜찮아\" 하고, 그게 다였어요!\t나는 아니라고 대답했고, 그것은 계속 이어졌다.\tcontradiction\n",
      "     그리고 저는 \"괜찮아\" 하고, 그게 다였어요!\t내가 좋다고 말했을 때, 우리는 그날 결혼하기로 결정했다.\tneutral\n",
      "     저는, 그냥 알아내려고 거기 있었어요.\t나는 처음부터 그것을 잘 이해했다.\tcontradiction\n",
      "     저는, 그냥 알아내려고 거기 있었어요.\t나는 돈이 어디로 갔는지 이해하려고 했어요.\tneutral\n",
      "     저는, 그냥 알아내려고 거기 있었어요.\t이해하려고 노력하고 있었어요.\tentailmentsentence1 sentence2 golden\n",
      "     .\n",
      "Human: 계획배합은 시험비빔을 해 정하고, 발주자 대리인의 지시에 따른다.\n",
      "Assistant:\n",
      "     그리고 그가 말했다, \"엄마, 저 왔어요.\"\t그는 estaba 버스가 그를 내려주자마자 엄마에게 전화를 크리스었다.\tysideral\n",
      "     그리고 그가 말했다, \"엄마, 저 왔어요.\"\t그는 엄마에게 집에 갔다고 말했다.\tentailment\n",
      "     내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 지정된 장소에 보고해야 했습니다.\t나는 워싱턴으로 진군하면서 해야 할 일이 무엇인지 정확히 있었다.\tcontradiction\n",
      "     내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 지정된 장소에 보고해야 했습니다.\t나는 내가 무엇을 할 것인지 확신할 수 없어서 내가 보고를 하도록 배정받은 워싱턴으로 recruit.\tentailment\n",
      "     그는 갈 수 없었다.\t그는 국민의 초대를 받은 사람이고 climbed 경험을 즐겼다.\t Chiadiction\n",
      "     그는 갈 수 없었다.\t그는 참석하는 것을 허가받지 않았다.\tentailment\n",
      "     그는 갈 수 없었다.\t그는 박물관 개관식에 가는 것이 허용되지 않았다.\tysideral\n",
      "     그리고 저는 \"괜찮아\" 하고, 그게 다였어요!\t내가ugg한\n"
     ]
    }
   ],
   "source": [
    "prompt_template = 'You are a natural language understanding assistant tasked with creating sentences for a dataset. Your job is to read the given first sentence and then generate three different second sentences: one that is neutral, one that is a contradiction, and one that is an entailment. \\\n",
    "    You need to make sentences in korean. \\\n",
    "    \\n This is examples: \\\n",
    "    sentence1\tsentence2\tgold_label \\\n",
    "    그리고 그가 말했다, \"엄마, 저 왔어요.\"\t그는 학교 버스가 그를 내려주자마자 엄마에게 전화를 걸었다.\tneutral\\n \\\n",
    "    그리고 그가 말했다, \"엄마, 저 왔어요.\"\t그는 한마디도 하지 않았다.\tcontradiction\\n \\\n",
    "    그리고 그가 말했다, \"엄마, 저 왔어요.\"\t그는 엄마에게 집에 갔다고 말했다.\tentailment\\n \\\n",
    "    내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 지정된 장소에 보고해야 했습니다.\t나는 워싱턴에 가본 적이 없어서 거기 배정을 받았을 때 그 장소를 찾으려다가 길을 잃었어요.\tneutral\\n \\\n",
    "    내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 지정된 장소에 보고해야 했습니다.\t워싱턴으로 진군하면서 해야 할 일이 무엇인지 정확히 알고 있었다.\tcontradiction\\n \\\n",
    "    내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 지정된 장소에 보고해야 했습니다.\t나는 내가 무엇을 할 것인지 확신할 수 없어서 내가 보고를 하도록 배정받은 워싱턴으로 갔다.\tentailment\\n \\\n",
    "    그는 갈 수 없었다.\t그는 처음 초대를 받은 사람이고 그 경험을 즐겼다.\tcontradiction\\n \\\n",
    "    그는 갈 수 없었다.\t그는 참석하는 것을 허가받지 않았다.\tentailment\\n \\\n",
    "    그는 갈 수 없었다.\t그는 박물관 개관식에 가는 것이 허용되지 않았다.\tneutral\\n \\\n",
    "    그리고 저는 \"괜찮아\" 하고, 그게 다였어요!\t내가 승낙한 후에, 그것은 끝났다.\tentailment\\n \\\n",
    "    그리고 저는 \"괜찮아\" 하고, 그게 다였어요!\t나는 아니라고 대답했고, 그것은 계속 이어졌다.\tcontradiction\\n \\\n",
    "    그리고 저는 \"괜찮아\" 하고, 그게 다였어요!\t내가 좋다고 말했을 때, 우리는 그날 결혼하기로 결정했다.\tneutral\\n \\\n",
    "    저는, 그냥 알아내려고 거기 있었어요.\t나는 처음부터 그것을 잘 이해했다.\tcontradiction\\n \\\n",
    "    저는, 그냥 알아내려고 거기 있었어요.\t나는 돈이 어디로 갔는지 이해하려고 했어요.\tneutral\\n \\\n",
    "    저는, 그냥 알아내려고 거기 있었어요.\t이해하려고 노력하고 있었어요.\tentailmentsentence1 sentence2 golden\\n \\\n",
    "    .\\nHuman: {prompt}\\nAssistant:\\n'\n",
    "text = '계획배합은 시험비빔을 해 정하고, 발주자 대리인의 지시에 따른다.'\n",
    "model_inputs = tokenizer(prompt_template.format(prompt=text), return_tensors='pt').to(device)\n",
    "\n",
    "outputs = model.generate(**model_inputs, max_new_tokens=256)\n",
    "output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
